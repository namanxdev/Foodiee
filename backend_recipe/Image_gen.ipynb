{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (0.35.3)\n",
      "Requirement already satisfied: filelock in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sJNc-3U6nbvO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import dotenv \n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "login(token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPS1R-Urncih",
    "outputId": "22782fa7-9d8f-44e4-e10e-64613236c6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Uninstalling old PyTorch version...\n",
      "Found existing installation: torch 2.9.0\n",
      "Uninstalling torch-2.9.0:\n",
      "  Successfully uninstalled torch-2.9.0\n",
      "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "üì• Installing PyTorch with CUDA 11.8 support...\n",
      "   (This may take 2-5 minutes...)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "üì• Installing Stable Diffusion libraries...\n",
      "Requirement already satisfied: diffusers in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (0.35.2)\n",
      "Requirement already satisfied: transformers in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: accelerate in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (1.10.1)\n",
      "Requirement already satisfied: safetensors in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (0.6.2)\n",
      "Requirement already satisfied: importlib_metadata in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from diffusers) (8.7.0)\n",
      "Requirement already satisfied: filelock in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from diffusers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.34.0 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from diffusers) (0.35.3)\n",
      "Requirement already satisfied: numpy in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from diffusers) (2.3.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from diffusers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from diffusers) (2.32.5)\n",
      "Requirement already satisfied: Pillow in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from diffusers) (12.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from accelerate) (7.1.0)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Using cached torch-2.9.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.34.0->diffusers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.34.0->diffusers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.34.0->diffusers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from importlib_metadata->diffusers) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from requests->diffusers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from requests->diffusers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from requests->diffusers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from requests->diffusers) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Using cached torch-2.9.0-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "‚úÖ Installation complete!\n",
      "\n",
      "‚ö†Ô∏è  IMPORTANT: After installation, please RESTART THE KERNEL\n",
      "   Then run the next cell to verify CUDA is working.\n",
      "\n",
      "üìã To restart kernel:\n",
      "   1. Click the 'Restart' button in the notebook toolbar, OR\n",
      "   2. Press Ctrl+Shift+P and search for 'Notebook: Restart Kernel'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install PyTorch with CUDA support for RTX 3050\n",
    "# Using CUDA 11.8 (most compatible version)\n",
    "\n",
    "print(\"üîÑ Uninstalling old PyTorch version...\")\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "print(\"\\nüì• Installing PyTorch with CUDA 11.8 support...\")\n",
    "print(\"   (This may take 2-5 minutes...)\")\n",
    "\n",
    "# Install PyTorch with CUDA 11.8 (most compatible with RTX 3050)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Step 2: Install required libraries for Stable Diffusion\n",
    "print(\"\\nüì• Installing Stable Diffusion libraries...\")\n",
    "!pip install diffusers transformers accelerate safetensors\n",
    "\n",
    "print(\"\\n‚úÖ Installation complete!\")\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: After installation, please RESTART THE KERNEL\")\n",
    "print(\"   Then run the next cell to verify CUDA is working.\")\n",
    "print(\"\\nüìã To restart kernel:\")\n",
    "print(\"   1. Click the 'Restart' button in the notebook toolbar, OR\")\n",
    "print(\"   2. Press Ctrl+Shift+P and search for 'Notebook: Restart Kernel'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç GPU DETECTION TEST\n",
      "============================================================\n",
      "PyTorch version: 2.9.0\n",
      "CUDA available: False\n",
      "\n",
      "‚ùå CUDA not detected!\n",
      "\n",
      "Possible reasons:\n",
      "1. ‚ö†Ô∏è  You haven't run cell 3 yet (CUDA installation)\n",
      "2. ‚ö†Ô∏è  NVIDIA GPU drivers not installed\n",
      "3. ‚ö†Ô∏è  GPU not recognized by Windows\n",
      "\n",
      "üí° Solutions:\n",
      "   ‚Ä¢ Run cell 3 to install PyTorch with CUDA support\n",
      "   ‚Ä¢ Update NVIDIA drivers from nvidia.com/drivers\n",
      "   ‚Ä¢ Restart your notebook kernel after installation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Quick GPU Detection Test - Run this to verify CUDA installation\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîç GPU DETECTION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\nüìä GPU {i} Information:\")\n",
    "        print(f\"   Name: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"   Total VRAM: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"   Compute Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Your GPU is ready for image generation!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå CUDA not detected!\")\n",
    "    print(\"\\nPossible reasons:\")\n",
    "    print(\"1. ‚ö†Ô∏è  You haven't run cell 3 yet (CUDA installation)\")\n",
    "    print(\"2. ‚ö†Ô∏è  NVIDIA GPU drivers not installed\")\n",
    "    print(\"3. ‚ö†Ô∏è  GPU not recognized by Windows\")\n",
    "    print(\"\\nüí° Solutions:\")\n",
    "    print(\"   ‚Ä¢ Run cell 3 to install PyTorch with CUDA support\")\n",
    "    print(\"   ‚Ä¢ Update NVIDIA drivers from nvidia.com/drivers\")\n",
    "    print(\"   ‚Ä¢ Restart your notebook kernel after installation\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188,
     "referenced_widgets": [
      "57a3bbe8709541f591fa793128357127",
      "6b28c2a2fbf64bba9ee4e96c06ba2763",
      "0f8865762ea94884a0b5b8dc91ffb390",
      "26f55bae7ca24a4ea05e167d4682af4b",
      "779da4ef20d24106858d0bdc95952513",
      "28b1e880d570412fab62f0b3c2ae1720",
      "266a451d7bb34332ad70bee4d0dcf245",
      "610e3ddcec7049548f3de0fc1021d85a",
      "1638d523e36d455fbdd607b58af562ce",
      "7a0bd550dd704f9680e9300c74404595",
      "4fe8016323db44b380e7223640e9a800",
      "338fa13877c04715b81d5b31360e39ce",
      "4f9f71f6f2d142c8a6074b3a4dd83f39",
      "10c45148ba494ea59bc803bf37570b62",
      "5bfa5c8d0bcf4e50b9206082786fab79",
      "840f0c14196c4b60acec0c4efc6eaec2",
      "571d2afeab864d4dbcf979805224ec1e",
      "d565735948bf4633990b65483441b7af",
      "802512390b17472992e4bebab930f24e",
      "87441366e19547ea8f84563ec87c4185",
      "b959816497df458da5fc29d073b18a2b",
      "2e331a1936394bd6b29cddbb02c83452"
     ]
    },
    "id": "E9IoaneznFmB",
    "outputId": "c8ef3276-4681-452a-9f7a-304a23d97d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üé® STABLE DIFFUSION - OPTIMIZED FOR YOUR SYSTEM\n",
      "================================================================================\n",
      "\n",
      "Detected OS: Darwin\n",
      "‚úÖ Using Apple Metal GPU (mps)\n",
      "   PyTorch will use Metal Performance Shaders for acceleration\n",
      "   Device: mps\n",
      "   Data type: torch.float32\n",
      "\n",
      "üì• Loading Stable Diffusion model...\n",
      "   (First time: ~4-5GB download)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 18.64it/s]\n",
      "\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (81 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', realistic texture .']\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (81 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', realistic texture .']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Enabling memory optimizations for mps...\n",
      "‚úÖ Memory optimizations enabled\n",
      "‚úÖ Model loaded successfully!\n",
      "\n",
      "üé® Generating image...\n",
      "   Prompt: 'Close-up, overhead full shot of finely chopped white onion and minced garlic bei...'\n",
      "   Steps: 30 (this may take 1-5 minutes on mps)\n",
      "   ‚è≥ Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [02:24<00:00,  4.82s/it]\n",
      "\n",
      "/Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages/diffusers/image_processor.py:148: RuntimeWarning: invalid value encountered in cast\n",
      "  images = (images * 255).round().astype(\"uint8\")\n",
      "/Users/chetanr/internship/Foodiee/.venv/lib/python3.12/site-packages/diffusers/image_processor.py:148: RuntimeWarning: invalid value encountered in cast\n",
      "  images = (images * 255).round().astype(\"uint8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Image generated successfully!\n",
      "   Time taken: 164.5 seconds\n",
      "   Saved as: cooking_scene.png\n",
      "   Resolution: 512x512\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=512x512>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Optimized for macOS with Apple Metal Performance Shaders (MPS)\n",
    "# If you're on Linux/Windows with NVIDIA GPU, use \"cuda\" instead of \"mps\"\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import gc\n",
    "import platform\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üé® STABLE DIFFUSION - OPTIMIZED FOR YOUR SYSTEM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Detect device\n",
    "os_name = platform.system()\n",
    "print(f\"\\nDetected OS: {os_name}\")\n",
    "\n",
    "if os_name == \"Darwin\" and torch.backends.mps.is_available():\n",
    "    # macOS with Metal GPU\n",
    "    device = \"mps\"\n",
    "    dtype = torch.float32  # Metal works best with float32\n",
    "    print(f\"‚úÖ Using Apple Metal GPU (mps)\")\n",
    "    print(f\"   PyTorch will use Metal Performance Shaders for acceleration\")\n",
    "    \n",
    "elif torch.cuda.is_available():\n",
    "    # Linux/Windows with NVIDIA GPU\n",
    "    device = \"cuda\"\n",
    "    dtype = torch.float16  # CUDA works great with float16\n",
    "    print(f\"‚úÖ Using NVIDIA GPU (cuda)\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "else:\n",
    "    # CPU fallback\n",
    "    device = \"cpu\"\n",
    "    dtype = torch.float32\n",
    "    print(f\"‚ö†Ô∏è  CPU only - image generation will be SLOW\")\n",
    "    print(f\"   Consider using a GPU for better performance\")\n",
    "\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Data type: {dtype}\")\n",
    "\n",
    "# Load model\n",
    "print(f\"\\nüì• Loading Stable Diffusion model...\")\n",
    "print(f\"   (First time: ~4-5GB download)\")\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=dtype,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False\n",
    ")\n",
    "\n",
    "# Move to device\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "# Enable memory optimizations\n",
    "if device in [\"cuda\", \"mps\"]:\n",
    "    print(f\"\\nüîß Enabling memory optimizations for {device}...\")\n",
    "    pipe.enable_attention_slicing()\n",
    "    if device == \"cuda\":\n",
    "        pipe.enable_vae_slicing()\n",
    "    print(\"‚úÖ Memory optimizations enabled\")\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\\n\")\n",
    "\n",
    "# Generate image\n",
    "prompt = \"Close-up, overhead full shot of finely chopped white onion and minced garlic being added to a hot, non-stick saut√© pan with a shimmer of olive oil. The pan is on a gas stovetop, with a soft, warm glow from the flame. Crisp, professional food photography, shallow depth of field, natural kitchen light, vibrant colors, highly detailed, realistic texture.\"\n",
    "\n",
    "print(\"üé® Generating image...\")\n",
    "print(f\"   Prompt: '{prompt[:80]}...'\")\n",
    "print(f\"   Steps: 30 (this may take 1-5 minutes on {device})\")\n",
    "print(f\"   ‚è≥ Please wait...\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    with torch.autocast(device):  # Auto-casting for better performance\n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            num_inference_steps=30,\n",
    "            guidance_scale=7.5,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Clear memory\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Save\n",
    "output_filename = \"cooking_scene.png\"\n",
    "image.save(output_filename)\n",
    "\n",
    "print(f\"\\n‚úÖ Image generated successfully!\")\n",
    "print(f\"   Time taken: {elapsed:.1f} seconds\")\n",
    "print(f\"   Saved as: {output_filename}\")\n",
    "print(f\"   Resolution: 512x512\")\n",
    "\n",
    "# Display\n",
    "from IPython.display import display\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîß CUDA DEBUGGING - Comprehensive System Diagnostics\n",
      "================================================================================\n",
      "\n",
      "0Ô∏è‚É£  OPERATING SYSTEM:\n",
      "   OS: Darwin\n",
      "   OS Release: 25.0.0\n",
      "   Architecture: arm64\n",
      "\n",
      "1Ô∏è‚É£  PYTHON ENVIRONMENT:\n",
      "   Python version: 3.12.4\n",
      "   Python executable: /Users/chetanr/internship/Foodiee/.venv/bin/python\n",
      "\n",
      "2Ô∏è‚É£  PYTORCH INSTALLATION:\n",
      "   ‚úÖ PyTorch is installed\n",
      "   PyTorch version: 2.9.0\n",
      "\n",
      "3Ô∏è‚É£  CUDA DETECTION:\n",
      "   torch.cuda.is_available(): False\n",
      "   torch.cuda.device_count(): 0\n",
      "\n",
      "4Ô∏è‚É£  NVIDIA GPU HARDWARE:\n",
      "   ‚ùå nvidia-smi NOT found (NVIDIA drivers may not be installed)\n",
      "\n",
      "5Ô∏è‚É£  SYSTEM GPU INFO:\n",
      "   Graphics/Displays:\n",
      "       Apple M1:\n",
      "         Chipset Model: Apple M1\n",
      "         Type: GPU\n",
      "         Bus: Built-In\n",
      "         Total Number of Cores: 8\n",
      "         Vendor: Apple (0x106b)\n",
      "         Metal Support: Metal 4\n",
      "         Displays:\n",
      "           Color LCD:\n",
      "             Display Type: Built-In Retina LCD\n",
      "             Resolution: 2560 x 1600 Retina\n",
      "             Main Display: Yes\n",
      "\n",
      "6Ô∏è‚É£  cuDNN STATUS:\n",
      "   torch.backends.cudnn.enabled: True\n",
      "   torch.backends.cudnn.is_available(): False\n",
      "\n",
      "================================================================================\n",
      "üìã DIAGNOSIS:\n",
      "================================================================================\n",
      "üçé YOU ARE ON macOS\n",
      "\n",
      "‚ùå PROBLEM: macOS does NOT support NVIDIA CUDA/GPUs\n",
      "\n",
      "   NVIDIA only officially supports CUDA on:\n",
      "   ‚úÖ Linux (various distributions)\n",
      "   ‚úÖ Windows\n",
      "   ‚ùå macOS (NOT supported)\n",
      "\n",
      "üîÑ ALTERNATIVES FOR macOS:\n",
      "\n",
      "   Option 1: Use Apple's Metal Performance Shaders (MPS)\n",
      "   - Built into PyTorch 1.12+\n",
      "   - Uses your MacBook's GPU efficiently\n",
      "   - Requires minimal setup\n",
      "\n",
      "   Option 2: Use CPU-only mode\n",
      "   - Slower but reliable\n",
      "   - Good for testing\n",
      "\n",
      "   Option 3: Run backend on a Linux/Windows GPU server\n",
      "   - Best performance\n",
      "   - Can offload image generation to cloud GPU\n",
      "\n",
      "================================================================================\n",
      "‚úÖ RECOMMENDED: Use Apple Metal for GPU acceleration on macOS\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================================================================\n",
    "# COMPREHENSIVE CUDA DEBUGGING\n",
    "# ========================================================================\n",
    "# This cell diagnoses why CUDA is not being detected\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üîß CUDA DEBUGGING - Comprehensive System Diagnostics\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# 0. Check OS first\n",
    "print(\"\\n0Ô∏è‚É£  OPERATING SYSTEM:\")\n",
    "print(f\"   OS: {platform.system()}\")\n",
    "print(f\"   OS Release: {platform.release()}\")\n",
    "print(f\"   Architecture: {platform.machine()}\")\n",
    "\n",
    "# 1. Check Python info\n",
    "print(\"\\n1Ô∏è‚É£  PYTHON ENVIRONMENT:\")\n",
    "print(f\"   Python version: {sys.version.split()[0]}\")\n",
    "print(f\"   Python executable: {sys.executable}\")\n",
    "\n",
    "# 2. Check if torch is installed and its version\n",
    "print(\"\\n2Ô∏è‚É£  PYTORCH INSTALLATION:\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"   ‚úÖ PyTorch is installed\")\n",
    "    print(f\"   PyTorch version: {torch.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"   ‚ùå PyTorch NOT installed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 3. Check CUDA-specific info\n",
    "print(\"\\n3Ô∏è‚É£  CUDA DETECTION:\")\n",
    "print(f\"   torch.cuda.is_available(): {torch.cuda.is_available()}\")\n",
    "print(f\"   torch.cuda.device_count(): {torch.cuda.device_count()}\")\n",
    "\n",
    "# 4. Check for NVIDIA GPU hardware\n",
    "print(\"\\n4Ô∏è‚É£  NVIDIA GPU HARDWARE:\")\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"   ‚úÖ nvidia-smi command works\")\n",
    "        lines = result.stdout.split('\\n')[:10]\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå nvidia-smi failed\")\n",
    "except FileNotFoundError:\n",
    "    print(\"   ‚ùå nvidia-smi NOT found (NVIDIA drivers may not be installed)\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error running nvidia-smi: {e}\")\n",
    "\n",
    "# 5. Check system GPU info\n",
    "print(\"\\n5Ô∏è‚É£  SYSTEM GPU INFO:\")\n",
    "try:\n",
    "    if platform.system() == \"Darwin\":  # macOS\n",
    "        result = subprocess.run(['system_profiler', 'SPDisplaysDataType'], \n",
    "                              capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            lines = result.stdout.split('\\n')[:15]\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# 6. cuDNN check\n",
    "print(\"\\n6Ô∏è‚É£  cuDNN STATUS:\")\n",
    "print(f\"   torch.backends.cudnn.enabled: {torch.backends.cudnn.enabled}\")\n",
    "try:\n",
    "    print(f\"   torch.backends.cudnn.is_available(): {torch.backends.cudnn.is_available()}\")\n",
    "except:\n",
    "    print(f\"   torch.backends.cudnn.is_available(): Not available in this PyTorch version\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìã DIAGNOSIS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    print(\"üçé YOU ARE ON macOS\")\n",
    "    print()\n",
    "    print(\"‚ùå PROBLEM: macOS does NOT support NVIDIA CUDA/GPUs\")\n",
    "    print()\n",
    "    print(\"   NVIDIA only officially supports CUDA on:\")\n",
    "    print(\"   ‚úÖ Linux (various distributions)\")\n",
    "    print(\"   ‚úÖ Windows\")\n",
    "    print(\"   ‚ùå macOS (NOT supported)\")\n",
    "    print()\n",
    "    print(\"üîÑ ALTERNATIVES FOR macOS:\")\n",
    "    print()\n",
    "    print(\"   Option 1: Use Apple's Metal Performance Shaders (MPS)\")\n",
    "    print(\"   - Built into PyTorch 1.12+\")\n",
    "    print(\"   - Uses your MacBook's GPU efficiently\")\n",
    "    print(\"   - Requires minimal setup\")\n",
    "    print()\n",
    "    print(\"   Option 2: Use CPU-only mode\")\n",
    "    print(\"   - Slower but reliable\")\n",
    "    print(\"   - Good for testing\")\n",
    "    print()\n",
    "    print(\"   Option 3: Run backend on a Linux/Windows GPU server\")\n",
    "    print(\"   - Best performance\")\n",
    "    print(\"   - Can offload image generation to cloud GPU\")\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"‚úÖ RECOMMENDED: Use Apple Metal for GPU acceleration on macOS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"‚úÖ CUDA IS AVAILABLE!\")\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA NOT AVAILABLE\")\n",
    "    print(\"   Likely cause: PyTorch CPU-only version installed\")\n",
    "    print(\"   Solution: Reinstall PyTorch with CUDA support\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üçé SETTING UP GPU ACCELERATION FOR macOS\n",
      "================================================================================\n",
      "\n",
      "OS: Darwin\n",
      "PyTorch version: 2.9.0\n",
      "\n",
      "üîç CHECKING METAL SUPPORT:\n",
      "‚úÖ torch.backends.mps module exists\n",
      "‚úÖ torch.backends.mps.is_available(): True\n",
      "‚úÖ torch.backends.mps.is_built(): True\n",
      "\n",
      "üéØ DEVICE RECOMMENDATION:\n",
      "‚úÖ Use device: 'mps' (Metal Performance Shaders)\n",
      "   ‚Ä¢ Fast GPU acceleration on macOS\n",
      "   ‚Ä¢ Built into PyTorch 1.12+\n",
      "   ‚Ä¢ Automatically uses your Mac's GPU\n",
      "\n",
      "üìä Testing device 'mps':\n",
      "‚úÖ Successfully created tensor on 'mps'\n",
      "   Tensor: torch.Size([3, 4])\n",
      "\n",
      "‚úÖ Ready to use device: mps\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================================================================\n",
    "# ‚ö†Ô∏è IMPORTANT: macOS GPU ACCELERATION WITH METAL\n",
    "# ========================================================================\n",
    "# Since you're on macOS, we'll use Apple Metal Performance Shaders instead of CUDA\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üçé SETTING UP GPU ACCELERATION FOR macOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(f\"\\nOS: {platform.system()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check if Metal is available\n",
    "print(\"\\nüîç CHECKING METAL SUPPORT:\")\n",
    "if hasattr(torch.backends, 'mps'):\n",
    "    print(f\"‚úÖ torch.backends.mps module exists\")\n",
    "    print(f\"‚úÖ torch.backends.mps.is_available(): {torch.backends.mps.is_available()}\")\n",
    "    print(f\"‚úÖ torch.backends.mps.is_built(): {torch.backends.mps.is_built()}\")\n",
    "else:\n",
    "    print(f\"‚ùå torch.backends.mps not available (PyTorch version too old)\")\n",
    "\n",
    "# Recommend device\n",
    "print(\"\\nüéØ DEVICE RECOMMENDATION:\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(f\"‚úÖ Use device: '{device}' (Metal Performance Shaders)\")\n",
    "    print(\"   ‚Ä¢ Fast GPU acceleration on macOS\")\n",
    "    print(\"   ‚Ä¢ Built into PyTorch 1.12+\")\n",
    "    print(\"   ‚Ä¢ Automatically uses your Mac's GPU\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(f\"‚ö†Ô∏è Fallback to: '{device}' (CPU)\")\n",
    "    print(\"   ‚Ä¢ Slower but works reliably\")\n",
    "    print(\"   ‚Ä¢ Update PyTorch to enable Metal support\")\n",
    "\n",
    "# Test the device\n",
    "print(f\"\\nüìä Testing device '{device}':\")\n",
    "try:\n",
    "    test_tensor = torch.randn(3, 4, device=device)\n",
    "    print(f\"‚úÖ Successfully created tensor on '{device}'\")\n",
    "    print(f\"   Tensor: {test_tensor.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    device = \"cpu\"\n",
    "    print(f\"   Falling back to CPU\")\n",
    "\n",
    "print(f\"\\n‚úÖ Ready to use device: {device}\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f8865762ea94884a0b5b8dc91ffb390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_610e3ddcec7049548f3de0fc1021d85a",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1638d523e36d455fbdd607b58af562ce",
      "value": 6
     }
    },
    "10c45148ba494ea59bc803bf37570b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_802512390b17472992e4bebab930f24e",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_87441366e19547ea8f84563ec87c4185",
      "value": 50
     }
    },
    "1638d523e36d455fbdd607b58af562ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "266a451d7bb34332ad70bee4d0dcf245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26f55bae7ca24a4ea05e167d4682af4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a0bd550dd704f9680e9300c74404595",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4fe8016323db44b380e7223640e9a800",
      "value": "‚Äá6/6‚Äá[00:00&lt;00:00,‚Äá‚Äá7.54it/s]"
     }
    },
    "28b1e880d570412fab62f0b3c2ae1720": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e331a1936394bd6b29cddbb02c83452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "338fa13877c04715b81d5b31360e39ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f9f71f6f2d142c8a6074b3a4dd83f39",
       "IPY_MODEL_10c45148ba494ea59bc803bf37570b62",
       "IPY_MODEL_5bfa5c8d0bcf4e50b9206082786fab79"
      ],
      "layout": "IPY_MODEL_840f0c14196c4b60acec0c4efc6eaec2"
     }
    },
    "4f9f71f6f2d142c8a6074b3a4dd83f39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_571d2afeab864d4dbcf979805224ec1e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d565735948bf4633990b65483441b7af",
      "value": "100%"
     }
    },
    "4fe8016323db44b380e7223640e9a800": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "571d2afeab864d4dbcf979805224ec1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57a3bbe8709541f591fa793128357127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b28c2a2fbf64bba9ee4e96c06ba2763",
       "IPY_MODEL_0f8865762ea94884a0b5b8dc91ffb390",
       "IPY_MODEL_26f55bae7ca24a4ea05e167d4682af4b"
      ],
      "layout": "IPY_MODEL_779da4ef20d24106858d0bdc95952513"
     }
    },
    "5bfa5c8d0bcf4e50b9206082786fab79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b959816497df458da5fc29d073b18a2b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2e331a1936394bd6b29cddbb02c83452",
      "value": "‚Äá50/50‚Äá[00:24&lt;00:00,‚Äá‚Äá2.08it/s]"
     }
    },
    "610e3ddcec7049548f3de0fc1021d85a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b28c2a2fbf64bba9ee4e96c06ba2763": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28b1e880d570412fab62f0b3c2ae1720",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_266a451d7bb34332ad70bee4d0dcf245",
      "value": "Loading‚Äápipeline‚Äácomponents...:‚Äá100%"
     }
    },
    "779da4ef20d24106858d0bdc95952513": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a0bd550dd704f9680e9300c74404595": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "802512390b17472992e4bebab930f24e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "840f0c14196c4b60acec0c4efc6eaec2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87441366e19547ea8f84563ec87c4185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b959816497df458da5fc29d073b18a2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d565735948bf4633990b65483441b7af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
